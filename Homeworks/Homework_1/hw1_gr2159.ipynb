{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework, please design, train, and evaluate a MLP (Multi-Layer Perceptron, aka Neural Network whose layers are all Linear layers) on the FashinMNIST data set.\n",
    "The dataset can be downloaded via PyTorch, just like how I downloaded the CIFAR-10 dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction and Importing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the most fundamental packages/modules of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import cv2\n",
    "import torch.nn.functional\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch essentially does two things:\n",
    "- Manipulates the so-called tensor data structure on GPU, just like NumPy can manipulate ndarray on CPU.\n",
    "- Provides a automatic differentiation engine and some convenient helper functions for deep learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor is a data structure that can be thought of as a generalization of a matrix. A grayscale image is a matrix, but a colored image with 3 channels can be thought of a tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we are using GPU. Computation will be very slow if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import some vision-related packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally some generic helper packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import cv2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sets a seed for the random number generators used by the random module, the numpy library, and the PyTorch library. By setting a seed, the code ensures that the results of the random number generation will be deterministic and reproducible, meaning that each time the code is run, the same sequence of random numbers will be generated. This is useful for debugging and testing, as well as for reproducing experimental results.\n",
    "\n",
    "Additionally, the code sets the device to either the GPU (if available) or the CPU. The PyTorch library allows computations to be performed on either the GPU or the CPU, and the device to be used can be specified by setting the device variable.\n",
    "\n",
    "Finally, the code sets torch.backends.cudnn.deterministic to True. This flag controls the deterministic behavior of the cuDNN library, which is used by PyTorch for GPU acceleration. By setting this flag to True, the code ensures that the cuDNN library will produce deterministic results and further improves the reproducibility of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work on our own model. A MLP (Multi-Layer Perceptron, aka Neural Network whose layers are all Linear layers) on the FashinMNIST data set.\n",
    "\n",
    "We will train out Linear_MLP on the FashinMNIST using consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "The classes are: \n",
    "\n",
    "0\tT-shirt/top\n",
    "\n",
    "1\tTrouser\n",
    "\n",
    "2\tPullover\n",
    "\n",
    "3\tDress\n",
    "\n",
    "4\tCoat\n",
    "\n",
    "5\tSandal\n",
    "\n",
    "6\tShirt\n",
    "\n",
    "7\tSneaker\n",
    "\n",
    "8\tBag\n",
    "\n",
    "9\tAnkle boot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset is included in PyTorch because it's so widely used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.data' # folder that contains the \n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do data augmentation. DL models are data hungry. A good trick to increse the size of dataset without the hardwork of acquiring/labeling more data is data augmentation. \n",
    "\n",
    "For each training image we will randomly rotate it (by up to 5 degrees), flip/mirror with probability 0.5, shift by +/-1 pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we compose all the data augmentation actions we want to do.\n",
    "# note that there is no need to do data augmentation on the testing set.\n",
    "train_transforms = [torchvision.transforms.RandomRotation(5),\n",
    "                  torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "                  torchvision.transforms.ToTensor()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Standardization\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it simple:\n",
    "\n",
    "***normalize***: making your data range in [0, 1]\n",
    "\n",
    "**standardize**: making your data's mean=0 and std=1\n",
    "\n",
    "In modern deep learning, sometimes it's often okay if you don't do these, but they will often help with faster training and better accuracy. Please see this [article](https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.data.float()\n",
    "means = train_dataset.data.mean(axis = (0)) / 255\n",
    "stds = train_dataset.data.std(axis = (0)) / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean and standard deviation of pixel values so we can standardize the dataset later. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply these transformations on our training set and testing set separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the standardization to the list of transformations we want to do.\n",
    "train_transforms.append(torchvision.transforms.Normalize(mean = means, std = stds))\n",
    "train_transforms = torchvision.transforms.Compose(train_transforms)\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='data/',\n",
    "                                                   train=True,\n",
    "                                                   transform=train_transforms,\n",
    "                                                   download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='data/',\n",
    "                                                  train=False,\n",
    "                                                  transform=test_transforms,\n",
    "                                                  download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave out 10% of data from the training set as the validation set. **The model won't train on the validation set, but only do inference on it.** \n",
    "\n",
    "Validation set is similar to test set (hence the similar transformations), but it's a good practice to only run your model on test set for only **once**, and use your validation set as a gauge of how well your model generalize while tweaking hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_dataset) * VALID_RATIO)\n",
    "n_valid_examples = len(train_dataset) - n_train_examples\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, \n",
    "                                           [n_train_examples, n_valid_examples])\n",
    "\n",
    "valid_dataset = copy.deepcopy(valid_dataset)\n",
    "valid_dataset.dataset.transform = test_transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to create a DataLoader object. \n",
    "\n",
    "DataLoader object can be thought of as an iterator we use in Python. Deep learning dataset are usually too large to fit on memory (RAM, usually 8GB to 32GB) entirely, so we want to have a DataLoader that can spit out a fixed size of the dataset every time we need more data to process.\n",
    "\n",
    "Batch_size can be thought of the number of data point we will ask the DataLoader to spit out. After DataLoader spit out a chunk partitioned from the entire dataset, we will send it to GPU's memory (VRAM) so GPU can work on it. Similarly, GPU has limited memory, usually ranging from a few GB to 40GB, so the number should be adjusted according to the VRAM of your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# we only shuffle the training set \n",
    "train_iterator = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=BATCH_SIZE, \n",
    "                                             shuffle=True)\n",
    "\n",
    "validation_iterator = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False)\n",
    "\n",
    "test_iterator = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is defining the model.\n",
    "\n",
    "Linear_MLP will have the following architecture:\n",
    "\n",
    "* There are 4 Fully connected linear layers (which serve as *feature extractors*), followed by 1 linear layers (which serve as the *classifier*).\n",
    "* All layers have `ReLU` activations. (Use `inplace=True` while defining your ReLUs.)\n",
    "\n",
    "* For the linear layers, the feature sizes are as follows:\n",
    "\n",
    "  - $1024 \\rightarrow 512 \\rightarrow 256 \\rightarrow 128 \\rightarrow 10$.\n",
    "\n",
    "  (The 10, of course, is because 10 is the number of classes in FashionMNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Linear_MLP model\n",
    "class Linear_MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear_MLP, self).__init__()\n",
    "        self.fully_connected_layer_1 = torch.nn.Linear(28 * 28, 1024)\n",
    "        self.fully_connected_layer_2 = torch.nn.Linear(1024, 512)\n",
    "        self.fully_connected_layer_3 = torch.nn.Linear(512, 256)\n",
    "        self.fully_connected_layer_4 = torch.nn.Linear(256, 128)\n",
    "        self.fully_connected_layer_5 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, image_tensor):\n",
    "        image_tensor = image_tensor.view(-1, 28 * 28)\n",
    "        image_tensor = torch.relu(self.fully_connected_layer_1(image_tensor))\n",
    "        image_tensor = torch.relu(self.fully_connected_layer_2(image_tensor))\n",
    "        image_tensor = torch.relu(self.fully_connected_layer_3(image_tensor))\n",
    "        image_tensor = torch.relu(self.fully_connected_layer_4(image_tensor))\n",
    "        image_tensor = self.fully_connected_layer_5(image_tensor)\n",
    "        return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_MLP()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training, we will need to initialize our models. To put it simple, we are assigning the intial values of weight. We could just assign them all 0 to start with, and it would work. But data scientists have come up with smarter ways to to this to make things work even better. \n",
    "\n",
    "For the linear layers we initialize using the *Xavier Normal* scheme, also known as *Glorot Normal*. For both types of layer we initialize the bias terms to zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear_MLP(\n",
       "  (fully_connected_layer_1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (fully_connected_layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fully_connected_layer_3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fully_connected_layer_4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fully_connected_layer_5): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a optimizer and loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the optimzer is called Adam. It's a slightly more advanced version of the common optimization algorithm called gradient descent. There are a few other optimizers out there, but for most common tasks we will just use Adam."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is the cross entropy loss. Notice that in our model definition, there is no activation function for the very last layer. This is because the loss function itself has softmax baked in to do multi-class classification. Part of the design choice is explained [here](https://stackoverflow.com/questions/57516027/does-pytorch-apply-softmax-automatically-in-nn-linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, y) in enumerate(iterator):\n",
    "        images = images.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(images)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- put our model into train mode with `model.train()`. Some layers should act differently during training than testing.\n",
    "\n",
    "For each iteration\n",
    "\n",
    "- acquire [batch_size] pairs of (image, label) from the data loader \n",
    "- send the data we just acquired to GPU.\n",
    "- clear the gradients calculated from the last iteration. \n",
    "- pass our batch of images, x, through to model to get predictions, y_pred\n",
    "- calculate the loss between our predictions and the actual labels\n",
    "- calculate the accuracy between our predictions and the actual labels\n",
    "- calculate the gradients of each parameter backward (hence backpropagation)\n",
    "- update the parameters by taking an optimizer step forward\n",
    "- update our metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (images, y) in iterator:\n",
    "    \n",
    "            images = images.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            accuracy = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation loop is similar to the training loop with a few differences:\n",
    "1. we put our model into evaluation mode with `model.eval()` for the same reason above.\n",
    "2. we wrap the iterations inside a `with torch.no_grad()` because for testing time we no longer need to calculate gradient, and we can save memory and computational time for not doing it.\n",
    "3. We also do not need to update our optimizer because we are no longer optimizing our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can start training. \n",
    "\n",
    "For each epoch, we run through the training process once to update our model. It's important to notice that the entire dataset is being run through once for just 1 training process. Then we use the updated model to run through the evaluation process to get our validation accuracy to gauge how well our model generalizes.\n",
    "\n",
    "We repeat this for 25 epochs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25\n",
      "Training Loss: 0.5600574032284354.. Validation Loss: 0.43378684574619253\n",
      "Training Accuracy: 0.8077730055527664.. Validtion Accuracy: 0.8389849295007422\n",
      "Time Elapsed: 0 in minute.. 14 in second\n",
      "\n",
      "Epoch: 2/25\n",
      "Training Loss: 0.4122523602221814.. Validation Loss: 0.4164559430581458\n",
      "Training Accuracy: 0.8532965541309655.. Validtion Accuracy: 0.849678634963137\n",
      "Time Elapsed: 0 in minute.. 12 in second\n",
      "\n",
      "Epoch: 3/25\n",
      "Training Loss: 0.37520327194818953.. Validation Loss: 0.366104356627515\n",
      "Training Accuracy: 0.8638366409952607.. Validtion Accuracy: 0.8643617021276596\n",
      "Time Elapsed: 0 in minute.. 12 in second\n",
      "\n",
      "Epoch: 4/25\n",
      "Training Loss: 0.35483999490314183.. Validation Loss: 0.3884074401031149\n",
      "Training Accuracy: 0.8748395537595614.. Validtion Accuracy: 0.8645279255319149\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 5/25\n",
      "Training Loss: 0.32781164094770404.. Validation Loss: 0.35412098657577595\n",
      "Training Accuracy: 0.8804119767453433.. Validtion Accuracy: 0.874501329787234\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 6/25\n",
      "Training Loss: 0.3126349413493798.. Validation Loss: 0.36796239398895425\n",
      "Training Accuracy: 0.8852685624248043.. Validtion Accuracy: 0.8709552307078179\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 7/25\n",
      "Training Loss: 0.30659131170802206.. Validation Loss: 0.4078477215259633\n",
      "Training Accuracy: 0.887946781247713.. Validtion Accuracy: 0.8612588656709549\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 8/25\n",
      "Training Loss: 0.289081898804807.. Validation Loss: 0.33069503592683913\n",
      "Training Accuracy: 0.8925009874088504.. Validtion Accuracy: 0.8822584221971795\n",
      "Time Elapsed: 0 in minute.. 12 in second\n",
      "\n",
      "Epoch: 9/25\n",
      "Training Loss: 0.28081805755106193.. Validation Loss: 0.3342591879215646\n",
      "Training Accuracy: 0.8966417357819905.. Validtion Accuracy: 0.8858599295007422\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 10/25\n",
      "Training Loss: 0.2699756812816265.. Validation Loss: 0.33175106251493414\n",
      "Training Accuracy: 0.9004060525747272.. Validtion Accuracy: 0.8803745571603167\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 11/25\n",
      "Training Loss: 0.26006351555234164.. Validation Loss: 0.3300695542959457\n",
      "Training Accuracy: 0.9044727488151659.. Validtion Accuracy: 0.8847517732610094\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 12/25\n",
      "Training Loss: 0.25208473569267736.. Validation Loss: 0.36024873933576523\n",
      "Training Accuracy: 0.9076693325669845.. Validtion Accuracy: 0.8769392732610094\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 13/25\n",
      "Training Loss: 0.2439103296282591.. Validation Loss: 0.34804724505607115\n",
      "Training Accuracy: 0.9078421208530806.. Validtion Accuracy: 0.8818151595744681\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 14/25\n",
      "Training Loss: 0.23714683115729507.. Validation Loss: 0.3359729913162424\n",
      "Training Accuracy: 0.9132355845652486.. Validtion Accuracy: 0.8841422872340425\n",
      "Time Elapsed: 0 in minute.. 31 in second\n",
      "\n",
      "Epoch: 15/25\n",
      "Training Loss: 0.22786530945008682.. Validation Loss: 0.36385003659636417\n",
      "Training Accuracy: 0.9157718701102723.. Validtion Accuracy: 0.8811502659574468\n",
      "Time Elapsed: 0 in minute.. 17 in second\n",
      "\n",
      "Epoch: 16/25\n",
      "Training Loss: 0.22866558071261192.. Validation Loss: 0.3430816446371535\n",
      "Training Accuracy: 0.9149140995260664.. Validtion Accuracy: 0.8865248231177635\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 17/25\n",
      "Training Loss: 0.21411399284633698.. Validation Loss: 0.3240311225836581\n",
      "Training Accuracy: 0.9206778239017415.. Validtion Accuracy: 0.8877437945376051\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 18/25\n",
      "Training Loss: 0.21135661966869193.. Validation Loss: 0.35381099280524764\n",
      "Training Accuracy: 0.9201964850391822.. Validtion Accuracy: 0.8842531030482434\n",
      "Time Elapsed: 0 in minute.. 14 in second\n",
      "\n",
      "Epoch: 19/25\n",
      "Training Loss: 0.2056312833193213.. Validation Loss: 0.34859910401258065\n",
      "Training Accuracy: 0.9228006516587678.. Validtion Accuracy: 0.8821476063829787\n",
      "Time Elapsed: 0 in minute.. 39 in second\n",
      "\n",
      "Epoch: 20/25\n",
      "Training Loss: 0.20075060465589378.. Validation Loss: 0.3548919644920116\n",
      "Training Accuracy: 0.9251518068720379.. Validtion Accuracy: 0.8914561170212766\n",
      "Time Elapsed: 0 in minute.. 45 in second\n",
      "\n",
      "Epoch: 21/25\n",
      "Training Loss: 0.19648369598551102.. Validation Loss: 0.33180786597918954\n",
      "Training Accuracy: 0.9266760466505566.. Validtion Accuracy: 0.8968860817716476\n",
      "Time Elapsed: 0 in minute.. 36 in second\n",
      "\n",
      "Epoch: 22/25\n",
      "Training Loss: 0.19668461945596463.. Validation Loss: 0.3663857178960709\n",
      "Training Accuracy: 0.9273054897785187.. Validtion Accuracy: 0.8846963656709549\n",
      "Time Elapsed: 0 in minute.. 25 in second\n",
      "\n",
      "Epoch: 23/25\n",
      "Training Loss: 0.18607854384540523.. Validation Loss: 0.3597061647538175\n",
      "Training Accuracy: 0.930971070347239.. Validtion Accuracy: 0.8932845744680851\n",
      "Time Elapsed: 0 in minute.. 39 in second\n",
      "\n",
      "Epoch: 24/25\n",
      "Training Loss: 0.1838619569007537.. Validation Loss: 0.3497913972018881\n",
      "Training Accuracy: 0.9323965739017415.. Validtion Accuracy: 0.8935062060964868\n",
      "Time Elapsed: 0 in minute.. 11 in second\n",
      "\n",
      "Epoch: 25/25\n",
      "Training Loss: 0.17747851880708648.. Validation Loss: 0.3759489703051587\n",
      "Training Accuracy: 0.933100069162405.. Validtion Accuracy: 0.8923980498567541\n",
      "Time Elapsed: 0 in minute.. 12 in second\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "# used to record history of the traning\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "validation_loss_history = []\n",
    "validation_accuracy_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time() # record start time\n",
    "\n",
    "    train_loss, train_acc = train(model=model, \n",
    "                                    iterator=train_iterator, \n",
    "                                    optimizer=optimizer, \n",
    "                                    criterion=criterion, \n",
    "                                    device=device)\n",
    "    torch.save(model, './model_'+str(epoch)+'.pt')\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_acc)\n",
    "    \n",
    "    validation_loss, validation_accuracy = evaluate(model=model, \n",
    "                                 iterator=validation_iterator, \n",
    "                                 criterion=criterion, \n",
    "                                 device=device)\n",
    "    \n",
    "    validation_loss_history.append(validation_loss) \n",
    "    validation_accuracy_history.append(validation_accuracy)\n",
    "    end_time = time.time()\n",
    "    minute, second = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{EPOCHS}') \n",
    "    print(f'Training Loss: {train_loss}.. Validation Loss: {validation_loss}')\n",
    "    print(f'Training Accuracy: {train_acc}.. Validtion Accuracy: {validation_accuracy}')\n",
    "    print(f'Time Elapsed: {minute} in minute.. {second} in second')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Linear_MLP()\n",
    "test_model = torch.load('model_24.pt', map_location=device)\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test accuracy is: 88.81369426751591 %\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = evaluate(model=test_model, \n",
    "                        iterator=test_iterator, \n",
    "                        criterion=criterion, \n",
    "                        device=device)\n",
    "print('Our test accuracy is:', test_acc*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  tensor([8, 8, 8], device='cuda:0')\n",
      "Actual labels:  tensor([1, 4, 7], device='cuda:0')\n",
      "Accuracy of the network on the local test images: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_29104\\768852388.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  test_images = torch.tensor(test_images, dtype=torch.float32) / 255\n"
     ]
    }
   ],
   "source": [
    "# Load test images from local folder\n",
    "test_images_folder = './test_images'\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for image_name in os.listdir(test_images_folder):\n",
    "    image = cv2.imread(os.path.join(test_images_folder, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    label = image_name.split('_')[0] # assuming that the label is the first part of the file name, separated by '_'\n",
    "    \n",
    "    test_images.append(image)\n",
    "    test_labels.append(int(label))\n",
    "\n",
    "# Convert the images to tensors and normalize\n",
    "test_images = torch.tensor(test_images, dtype=torch.float32) / 255\n",
    "test_images = test_images.view(-1, 1, 28, 28)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Move all tensors to the same device\n",
    "test_model = test_model.to(device)\n",
    "test_images = test_images.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "# Evaluate the model on the test images\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = test_model(test_images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(\"Predicted labels: \", predicted)\n",
    "    print(\"Actual labels: \", test_labels)\n",
    "\n",
    "    correct = (predicted == test_labels).sum().item()\n",
    "    accuracy = correct / len(test_labels)\n",
    "\n",
    "print(f'Accuracy of the network on the local test images: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_vision_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28a7dcf41b89ceea79881175bec7b6a3063007774e7dd4410f2273c31f9b85b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
